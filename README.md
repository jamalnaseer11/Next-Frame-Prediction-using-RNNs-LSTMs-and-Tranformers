Predicting and Generating Video Sequences Using Deep Learning
This project focuses on video prediction, where a deep learning model generates future video frames based on short input sequences. By leveraging the UCF101 dataset (a collection of human activity videos), the model learns temporal patterns and motion dynamics to predict and synthesize upcoming frames.

Technologies Used
Python, PyTorch – Model training and deep learning framework
OpenCV, MoviePy – Video processing and frame extraction
Streamlit, Gradio, Flask – Interactive web applications for model deployment and visualization
Key Features
✅ Predicts and generates future video frames from an input sequence
✅ Trained on UCF101 human activity dataset for real-world applicability
✅ Utilizes deep learning architectures to capture motion patterns
✅ Provides an interactive web-based interface for user input and visualization

This project demonstrates computer vision, sequence modeling, and deep learning techniques, making it a valuable tool for research in autonomous systems, action recognition, and video synthesis. 
